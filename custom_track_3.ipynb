{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278cfd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from IPython.display import Image, clear_output  # to display images\n",
    "\n",
    "clear_output()\n",
    "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")\n",
    "\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6567d299",
   "metadata": {},
   "source": [
    "# MOT Evaluation using BoxMOT (Wide Format Output)\n",
    "\n",
    "This notebook performs Multi-Object Tracking (MOT) evaluation using the `boxmot` library and custom weights on a dataset structured in MOT17 format.\n",
    "\n",
    "**Workflow:**\n",
    "1.  **Setup:** Install necessary libraries and import modules.\n",
    "2.  **Configuration:** Define paths to the dataset, weights, output directory, and algorithms to test.\n",
    "3.  **Run Tracking:** Execute `boxmot` for each specified algorithm on all test sequences. This generates tracking result files (`.txt`) and visualization videos (`.mp4`).\n",
    "4.  **Run Evaluation:** Calculate quantitative MOT metrics (MOTA, IDF1, IDSW, GT_IDs, Count-IDs) for each sequence using `motmetrics`.\n",
    "5.  **Aggregate Results:** Combine results into a wide-format table where rows are algorithms and columns show metrics per sequence and overall summary metrics.\n",
    "6.  **Display Results:** Show the final table and save it to a CSV file.\n",
    "7.  **Qualitative Info:** List the paths to the generated visualization videos.\n",
    "8.  **Plotting:** Provide example code to generate comparison plots from the results.\n",
    "\n",
    "**Metrics:**\n",
    "* **MOTA:** Multiple Object Tracking Accuracy\n",
    "* **IDF1:** ID F1 Score (measures ID consistency)\n",
    "* **IDSW:** Number of ID Switches\n",
    "* **GT_IDs:** Number of unique Ground Truth object IDs in the sequence\n",
    "* **Count-IDs:** Number of unique Track IDs generated by the tracker in the sequence\n",
    "* **Combined_MOTA/IDF1:** Metrics calculated over all sequences combined (more robust than simple averaging)\n",
    "* **Total_IDSW/GT_IDs/Count-IDs:** Sum of switches/IDs across all sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b323d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "# - boxmot: For running the trackers\n",
    "# - motmetrics: For calculating evaluation metrics\n",
    "# - pandas: For data manipulation and table display\n",
    "# - matplotlib: For plotting results\n",
    "import sys\n",
    "# !{sys.executable} -m pip install boxmot motmetrics pandas matplotlib numpy\n",
    "import sys\n",
    "# !{sys.executable} -m pip install --force-reinstall --no-cache-dir 'ultralytics @ git+https://github.com/mikel-brostrom/ultralytics.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee115405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# !{sys.executable} -m pip install \"pandas<2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b60995a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries  cell1\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import logging\n",
    "import motmetrics as mm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # For plotting later\n",
    "import os\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "log = logging.getLogger()\n",
    "\n",
    "# Configure pandas display options for wider tables\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000) # Adjust console width if needed\n",
    "pd.set_option('display.float_format', '{:.3f}'.format) # Set default float format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d3a4fe",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "**Important:** Update the following paths and parameters according to your setup.\n",
    "* `dataset_root`: Path to your MOT-formatted dataset (containing the `test` folder).\n",
    "* `output_dir`: Directory where results (tracking files, videos, CSV) will be saved.\n",
    "* `algorithms`: List of tracker names supported by `boxmot` (e.g., 'ByteTrack', 'BoTSORT', 'DeepOCSORT').\n",
    "* `det_weights`: Path to your trained detection model weights (`.pt` file).\n",
    "* `reid_weights`: Path to your trained Re-ID model weights (`.pt` file).\n",
    "* `conf_threshold`: Confidence threshold for detection during tracking.\n",
    "* `iou_threshold`: IoU threshold used by `motmetrics` for matching detections to ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb79812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---     cell2\n",
    "# !!! PLEASE UPDATE THESE PATHS AND PARAMETERS !!!\n",
    "dataset_root = '/home/kms2069/Projects/boxmot/assets/polyp_test_mot' # e.g., './personal_dataset'\n",
    "output_dir = 'runs/mot_eval_notebook'\n",
    "algorithms = ['ByteTrack', 'BoTSORT', 'DeepOCSORT'] # Trackers to evaluate\n",
    "det_weights = 'yolov8m_polypPNG7.4_best.pt' # e.g., './weights/yolov8n_person.pt'\n",
    "reid_weights = 'osnet_ain_x1_0_polyp.pt' # e.g., 'osnet_x0_25_msmt17.pt'\n",
    "\n",
    "conf_threshold = 0.82 # Detection confidence threshold for tracker\n",
    "iou_threshold = 0.7 # IoU threshold for motmetrics matching\n",
    "device = '0' # Set GPU device if needed, otherwise uses CPU by default in boxmot\n",
    "# --------------------\n",
    "\n",
    "# --- Path Setup ---\n",
    "dataset_root = Path(dataset_root)\n",
    "output_base_dir = Path(output_dir)\n",
    "det_weights = Path(det_weights)\n",
    "reid_weights = Path(reid_weights)\n",
    "test_dir = dataset_root / 'test'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_base_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --- Validation ---\n",
    "if not test_dir.is_dir():\n",
    "    log.error(f\"Dataset test directory not found: {test_dir}\")\n",
    "    # Stop execution or raise error in a notebook context if needed\n",
    "    assert False, f\"Dataset test directory not found: {test_dir}\"\n",
    "if not det_weights.is_file():\n",
    "    log.warning(f\"Detection weights file not found: {det_weights}\")\n",
    "    # Depending on the tracker, this might be an error\n",
    "if not reid_weights.is_file() and any(algo in ['BoTSORT', 'DeepOCSORT'] for algo in algorithms):\n",
    "     log.warning(f\"ReID weights file not found: {reid_weights}, but required by BoTSORT/DeepOCSORT\")\n",
    "     # This might cause errors later for ReID-based trackers\n",
    "\n",
    "log.info(f\"Dataset Root: {dataset_root}\")\n",
    "log.info(f\"Output Directory: {output_base_dir}\")\n",
    "log.info(f\"Algorithms to Test: {algorithms}\")\n",
    "log.info(f\"Detection Weights: {det_weights}\")\n",
    "log.info(f\"ReID Weights: {reid_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e744385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help function?    cell3\n",
    "def count_unique_ids_from_file(filepath):\n",
    "    \"\"\"Counts the number of unique track IDs from a MOT result file.\"\"\"\n",
    "    if not filepath.is_file():\n",
    "        log.warning(f\"Tracker file not found for counting IDs: {filepath}\")\n",
    "        return 0\n",
    "    try:\n",
    "        # Try reading with comma separator first, then fallback to whitespace\n",
    "        try:\n",
    "            data = pd.read_csv(filepath, header=None, sep=',')\n",
    "        except pd.errors.ParserError:\n",
    "            data = pd.read_csv(filepath, header=None, sep='\\s+', engine='python')\n",
    "\n",
    "        # MOT format: ID is the 2nd column (index 1)\n",
    "        if data.empty or 1 not in data.columns:\n",
    "            log.warning(f\"Tracker file seems empty or has unexpected format: {filepath}\")\n",
    "            return 0\n",
    "        unique_ids = data[1].unique()\n",
    "        # Optionally exclude invalid IDs like -1 if they appear\n",
    "        unique_ids = unique_ids[unique_ids != -1]\n",
    "        return len(unique_ids)\n",
    "    except Exception as e:\n",
    "        log.error(f\"Error reading or processing tracker file {filepath}: {e}\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f0f34a",
   "metadata": {},
   "source": [
    "## 3. Run Tracking\n",
    "\n",
    "This cell iterates through the specified algorithms and test sequences, running the `boxmot.track` command using `subprocess`. This generates `.txt` tracking results and `.mp4` visualization videos in the output directory.\n",
    "\n",
    "**Note:** This step can take a significant amount of time depending on the number of sequences, their length, and the chosen algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31986c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수정 전 cell 5. 실행 전 유의. 실행 전 유의. 실행 전 유의. 실행 전 유의\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# log = logging.getLogger(__name__) # 로거 가져오기     실행시킬려면 # 제거거\n",
    "\n",
    "# 현재 커널의 파이썬 실행 파일 경로 확인\n",
    "python_executable = sys.executable\n",
    "log.info(f\"Using Python executable: {python_executable}\")\n",
    "if 'envs/boxmot/bin/python' not in python_executable:\n",
    "    log.warning(f\"Python executable ({python_executable}) might not be from the expected 'boxmot' env. Please check Jupyter kernel selection.\")\n",
    "\n",
    "cloned_boxmot_repo_path = 'tracking' # <--- 실제 클론된 boxmot 폴더 경로로 변경하세요!\n",
    "track_script_path = os.path.join(cloned_boxmot_repo_path, 'track.py')\n",
    "\n",
    "# --- track.py 존재 여부 확인 ---\n",
    "if not os.path.isfile(track_script_path):\n",
    "    log.error(f\"Manually specified 'track.py' path not found: {track_script_path}\")\n",
    "    log.error(\"Please ensure the path in 'cloned_boxmot_repo_path' is correct and points to the cloned boxmot repository directory.\")\n",
    "    log.error(\"You can clone it using: git clone https://github.com/mikel-brostrom/boxmot.git\")\n",
    "    assert False, \"'track.py' not found at the specified path.\"\n",
    "else:\n",
    "    log.info(f\"Using tracker script from cloned repository: {track_script_path}\")\n",
    "\n",
    "# cloned_boxmot_repo_path ('tracking')의 부모 디렉토리 계산\n",
    "execution_cwd = os.path.dirname(cloned_boxmot_repo_path) # 'tracking'의 부모 -> '' (현재 디렉토리 의미)가 될 수 있음\n",
    "# 빈 문자열일 경우 현재 디렉토리('.')로 처리하고 절대 경로화\n",
    "if not execution_cwd:\n",
    "    execution_cwd = '.'\n",
    "execution_cwd = os.path.abspath(execution_cwd)\n",
    "log.info(f\"Setting execution CWD for subprocess to: {execution_cwd}\")\n",
    "\n",
    "# PYTHONPATH 설정: CWD (즉, 'tracking' 폴더의 부모)를 PYTHONPATH에 추가\n",
    "my_env = os.environ.copy() # 현재 환경 변수 복사\n",
    "# execution_cwd 경로를 PYTHONPATH의 시작 부분에 추가 (기존 PYTHONPATH가 있으면 뒤에 붙임)\n",
    "existing_pythonpath = my_env.get('PYTHONPATH', '')\n",
    "my_env['PYTHONPATH'] = execution_cwd + os.pathsep + existing_pythonpath\n",
    "log.info(f\"Setting PYTHONPATH for subprocess to include: {execution_cwd}\")\n",
    "# log.debug(f\"Full PYTHONPATH for subprocess: {my_env['PYTHONPATH']}\") # 디버깅 시 전체 경로 확인\n",
    "\n",
    "\n",
    "log.info(\"--- Starting Tracking Process ---\")\n",
    "tracking_failed = False\n",
    "script_found = True\n",
    "\n",
    "# --- output_base_dir 절대 경로 변환 ---\n",
    "# cwd가 변경되므로, 상대 경로였던 output 경로는 절대 경로로 지정하는 것이 안전함\n",
    "output_base_dir = Path(output_dir).resolve()\n",
    "log.info(f\"Using absolute output base directory: {output_base_dir}\")\n",
    "\n",
    "\n",
    "for algo in algorithms:\n",
    "    log.info(f\"Running tracking for algorithm: {algo}\")\n",
    "    algo_output_dir_check = output_base_dir / algo\n",
    "    sequences = sorted([d for d in test_dir.iterdir() if d.is_dir() and (d / 'seqinfo.ini').exists()])\n",
    "    if not sequences:\n",
    "        log.warning(f\"No valid sequences found in {test_dir}\")\n",
    "        continue\n",
    "\n",
    "    for seq_path in sequences:\n",
    "        seq_name = seq_path.name\n",
    "        abs_seq_path = seq_path.resolve()\n",
    "        log.info(f\"  Processing sequence: {seq_name}\")\n",
    "\n",
    "        # --- 절대 경로로 저장될 경로 확인 ---\n",
    "        project_path = output_base_dir / algo # 절대 경로\n",
    "        trk_file_path = project_path / seq_name / 'tracks' / f\"{seq_name}.txt\"\n",
    "        vid_file_path = project_path / seq_name / 'tracks' / f\"{seq_name}.mp4\"\n",
    "\n",
    "        # 결과 존재 여부 확인 (절대 경로 기준)\n",
    "        if trk_file_path.exists() and vid_file_path.exists():\n",
    "            log.info(f\"    Skipping {seq_name} for {algo} - Results already exist at {project_path / seq_name}.\")\n",
    "            continue\n",
    "\n",
    "        # --- Construct command using the track.py script from clone ---\n",
    "        cmd = [\n",
    "            python_executable,       # 현재 커널의 파이썬 사용\n",
    "            track_script_path,       # 수동 지정된 track.py 경로\n",
    "            f'--source', str(abs_seq_path / \"img1\"),\n",
    "            f'--tracking-method', algo.lower(),\n",
    "            # --- 수정된 인자 이름 ---\n",
    "            f'--yolo-model', str(det_weights.resolve()),    # <-- '--weights' 대신 사용\n",
    "            f'--reid-model', str(reid_weights.resolve()),    # <-- '--reid-weights' 대신 사용\n",
    "            # --- 수정된 인자 이름 끝 ---\n",
    "            f'--project', str(project_path),\n",
    "            f'--name', seq_name,\n",
    "            '--save-txt',                                  # <-- 인식되었으므로 유지\n",
    "            # '--save-vid',                                # <-- 인식 안됨, 제거\n",
    "            '--save',                                      # <-- '--save-vid' 대신 '--save' 사용 (스크립트 도움말에 있음)\n",
    "            f'--conf', str(conf_threshold),\n",
    "        ]\n",
    "        if 'device' in locals() and device is not None:\n",
    "             cmd.extend([f'--device', str(device)])\n",
    "\n",
    "        try:\n",
    "            log.info(f\"    Executing command: {' '.join(cmd)}\")\n",
    "            # --- 중요: 실행 경로 변경 (선택 사항) ---\n",
    "            # track.py가 다른 모듈(예: boxmot 패키지)을 상대 경로로 import하는 경우,\n",
    "            # 스크립트가 있는 디렉토리에서 실행해야 할 수 있습니다.\n",
    "            # cwd = os.path.dirname(track_script_path) # track.py가 있는 디렉토리\n",
    "            # result = subprocess.run(cmd, check=True, capture_output=True, text=True, encoding='utf-8', cwd=cwd)\n",
    "            # --- 또는 경로 변경 없이 실행 ---\n",
    "            log.info(f\"    >>> in CWD: {execution_cwd} | with PYTHONPATH including: {execution_cwd}\")\n",
    "            # --- *** 실행 시 cwd 및 수정된 env 전달 *** ---\n",
    "            result = subprocess.run(cmd, check=True, capture_output=True, text=True,\n",
    "                                    encoding='utf-8', cwd=execution_cwd, env=my_env) # <--- env=my_env 전달\n",
    "\n",
    "            log.info(f\"    Successfully tracked {seq_name} with {algo}.\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            log.error(f\"    Error running tracker script for {seq_name} with {algo} (CWD: {execution_cwd}):\")\n",
    "            log.error(f\"    Return code: {e.returncode}\")\n",
    "            log.error(f\"    Stderr: {e.stderr.strip()}\")\n",
    "            log.error(f\"    Stdout: {e.stdout.strip()}\")\n",
    "            tracking_failed = True\n",
    "        except FileNotFoundError:\n",
    "             log.error(f\"    Error: '{python_executable}' or script '{track_script_path}' not found.\")\n",
    "             tracking_failed = True\n",
    "             script_found = False\n",
    "             break\n",
    "    if not script_found:\n",
    "        break\n",
    "\n",
    "    if tracking_failed:\n",
    "        log.warning(f\"Some tracking processes failed for algorithm {algo}. Evaluation might be incomplete.\")\n",
    "        if script_found: tracking_failed = False\n",
    "\n",
    "log.info(\"--- Tracking Process Finished ---\")\n",
    "\n",
    "# 최종적으로 스크립트를 못찾아서 중단된 경우 에러 발생\n",
    "if not script_found:\n",
    "    log.critical(\"Tracking process aborted because the track script ('track.py' or 'boxmot-track') was not found in the environment bin.\")\n",
    "    assert False, \"Tracking script not found.\"\n",
    "elif tracking_failed:\n",
    "    # 스크립트는 찾았지만 일부 시퀀스/알고리즘 실패 시 경고만 표시\n",
    "    log.warning(\"Overall tracking process completed, but note that some sequences/algorithms may have failed during execution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7b5104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 5 (수정됨 - val.py 워크플로우용 설정) ---\n",
    "\n",
    "from pathlib import Path\n",
    "import torch # torch.cuda.is_available() 사용 위해\n",
    "\n",
    "# --- 기본 경로 설정 ---\n",
    "# val.py, track.py 및 관련 모듈(detectors, utils 등)이 포함된 폴더 경로\n",
    "# 사용자가 'tracking'으로 지정함. 현재 노트북 파일 위치 기준 상대 경로라고 가정.\n",
    "cloned_boxmot_repo_path = 'tracking'\n",
    "\n",
    "# 데이터셋 루트 경로\n",
    "# 예: './personal_dataset' 또는 '/path/to/your/personal_dataset'\n",
    "dataset_root_path = '/home/kms2069/Projects/boxmot/assets/polyp_test_mot' # <--- 실제 데이터셋 루트 경로로 수정\n",
    "\n",
    "# 결과 저장 기본 디렉토리\n",
    "output_dir = 'runs/mot_eval_notebook_val' # 이전 실행과 구분하기 위해 이름 변경 권장\n",
    "\n",
    "# --- 모델 가중치 경로 ---\n",
    "# .resolve()를 사용하여 절대 경로로 만드는 것이 안전함\n",
    "det_weights = Path('/home/kms2069/Projects/boxmot/yolov8m_polypPNG7.4_best.pt').resolve() # <--- 실제 경로로 수정\n",
    "reid_weights = Path('/home/kms2069/Projects/boxmot/osnet_ain_x1_0_polyp.pt').resolve() # <--- 실제 경로로 수정\n",
    "\n",
    "# --- 추적 및 평가 설정 ---\n",
    "# 평가할 추적 알고리즘 리스트\n",
    "algorithms = ['ByteTrack', 'BoTSORT', 'DeepOCSORT']\n",
    "\n",
    "# 처리할 테스트셋 디렉토리 경로 (val.py의 --source 인자에 해당)\n",
    "test_set_dir = Path(dataset_root_path) / 'test' # 예: /path/to/dataset/test\n",
    "\n",
    "# --- 하이퍼파라미터 ---\n",
    "# val.py의 기본값은 0.01 임. 필요시 조정.\n",
    "conf_threshold = 0.82 # 사용자가 이전에 사용한 값 유지 0.82\n",
    "# val.py의 기본값은 0.7 임. 필요시 조정.\n",
    "iou_threshold = 0.7 # NMS IoU (Stage 1에서 사용) 0.55\n",
    "\n",
    "# --- 실행 환경 ---\n",
    "# '0', '1', 'cpu' 등. 비워두면 자동 선택 가능성 있음.\n",
    "device = '0' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# --- Cell 5 변수 검증 ---\n",
    "assert Path(cloned_boxmot_repo_path).is_dir(), f\"Tracking script directory not found: {cloned_boxmot_repo_path}\"\n",
    "assert dataset_root_path is not None and Path(dataset_root_path).is_dir(), f\"Dataset root directory not found: {dataset_root_path}\"\n",
    "assert test_set_dir.is_dir(), f\"Test set directory not found: {test_set_dir}\"\n",
    "assert det_weights.is_file(), f\"Detection weights not found: {det_weights}\"\n",
    "assert reid_weights.is_file(), f\"ReID weights not found: {reid_weights}\"\n",
    "\n",
    "# 로그 출력 (옵션)\n",
    "log.info(f\"Configuration Loaded:\")\n",
    "log.info(f\"  Tracking Scripts Path: {cloned_boxmot_repo_path}\")\n",
    "log.info(f\"  Dataset Root: {dataset_root_path}\")\n",
    "log.info(f\"  Test Set Dir (--source): {test_set_dir}\")\n",
    "log.info(f\"  Output Directory: {output_dir}\")\n",
    "log.info(f\"  YOLO Model: {det_weights}\")\n",
    "log.info(f\"  ReID Model: {reid_weights}\")\n",
    "log.info(f\"  Algorithms: {algorithms}\")\n",
    "log.info(f\"  Confidence Threshold: {conf_threshold}\")\n",
    "log.info(f\"  Device: {device}\")\n",
    "\n",
    "# Cell 6, 7, 8에서 사용할 변수들 정의 (명확성을 위해)\n",
    "output_base_dir = Path(output_dir) # Path 객체로 변환\n",
    "val_script_path = Path(os.path.abspath(os.path.join(cloned_boxmot_repo_path, 'val.py'))) # val.py 절대 경로\n",
    "execution_cwd = Path(os.path.abspath(os.path.dirname(cloned_boxmot_repo_path))) # CWD\n",
    "my_env = os.environ.copy() # 환경 변수 복사\n",
    "existing_pythonpath = my_env.get('PYTHONPATH', '')\n",
    "my_env['PYTHONPATH'] = str(execution_cwd) + os.pathsep + existing_pythonpath # PYTHONPATH 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc3143c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 6: Stage 1: Generate Detections & Embeddings ---\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "python_executable = sys.executable\n",
    "\n",
    "# --- val.py 경로 설정 ---\n",
    "# val.py가 track.py와 같은 위치에 있다고 가정\n",
    "val_script_path = os.path.abspath(os.path.join(cloned_boxmot_repo_path, 'val.py')) # cloned_boxmot_repo_path는 Cell 5에서 정의됨\n",
    "if not os.path.isfile(val_script_path):\n",
    "    log.error(f\"'val.py' not found at expected path: {val_script_path}\")\n",
    "    assert False, \"'val.py' not found.\"\n",
    "else:\n",
    "    log.info(f\"Using val script: {val_script_path}\")\n",
    "\n",
    "# --- Stage 1 실행 ---\n",
    "log.info(\"--- Stage 1: Generating Detections and Embeddings ---\")\n",
    "# val.py는 여러 yolo/reid 모델을 받을 수 있지만, 여기서는 첫 번째 모델만 사용한다고 가정\n",
    "# Cell 5에서 yolo_model, reid_model이 리스트가 아닐 경우 리스트로 변환 필요할 수 있음\n",
    "# 예시: yolo_weights_list = [det_weights] if not isinstance(det_weights, list) else det_weights\n",
    "# 예시: reid_weights_list = [reid_weights] if not isinstance(reid_weights, list) else reid_weights\n",
    "# 여기서는 Cell 5의 변수가 이미 Path 객체라고 가정하고 문자열로 변환\n",
    "\n",
    "# --- CWD 및 PYTHONPATH 설정 (val.py도 필요할 수 있음) ---\n",
    "execution_cwd = os.path.abspath(os.path.dirname(cloned_boxmot_repo_path)) # val.py가 있는 폴더의 부모\n",
    "my_env = os.environ.copy()\n",
    "existing_pythonpath = my_env.get('PYTHONPATH', '')\n",
    "my_env['PYTHONPATH'] = execution_cwd + os.pathsep + existing_pythonpath\n",
    "log.info(f\"Using CWD: {execution_cwd}, adding to PYTHONPATH for val.py\")\n",
    "\n",
    "# --- generate_dets_embs 명령어 구성 ---\n",
    "cmd_stage1 = [\n",
    "    python_executable,\n",
    "    val_script_path,\n",
    "    'generate_dets_embs', # Subparser command\n",
    "    '--source', str(test_dir.resolve()), # test 폴더 경로 (절대 경로)\n",
    "    '--yolo-model', str(det_weights.resolve()), # 첫 번째 YOLO 모델\n",
    "    '--reid-model', str(reid_weights.resolve()), # 첫 번째 ReID 모델\n",
    "    '--project', str(output_base_dir.resolve()), # 저장 경로 (절대 경로)\n",
    "    # '--name', '', # val.py는 name을 어떻게 사용하는지 확인 필요 (기본값 사용 또는 설정)\n",
    "    '--exist-ok', # 덮어쓰기 허용 (val.py 기본값 확인 필요, 여기서는 True로 가정)\n",
    "    f'--conf', str(conf_threshold),\n",
    "    # '--imgsz', '640', # 필요시 imgsz 설정 (val.py 기본값 또는 Cell 5 설정 사용)\n",
    "    # '--classes', '0', # 필요시 class 설정 (val.py 기본값 또는 Cell 5 설정 사용)\n",
    "]\n",
    "if 'device' in locals() and device is not None:\n",
    "    cmd_stage1.extend(['--device', str(device)])\n",
    "\n",
    "try:\n",
    "    log.info(f\"Executing Stage 1 command: {' '.join(cmd_stage1)}\")\n",
    "    result_stage1 = subprocess.run(cmd_stage1, check=True, capture_output=True, text=True,\n",
    "                                   encoding='utf-8', cwd=execution_cwd, env=my_env)\n",
    "    log.info(\"--- Stage 1 Finished Successfully ---\")\n",
    "    # log.debug(f\"Stage 1 Stdout: {result_stage1.stdout}\") # 필요시 출력 확인\n",
    "except subprocess.CalledProcessError as e:\n",
    "    log.error(f\"--- Stage 1 FAILED ---\")\n",
    "    log.error(f\"Return code: {e.returncode}\")\n",
    "    log.error(f\"Stderr: {e.stderr.strip()}\")\n",
    "    log.error(f\"Stdout: {e.stdout.strip()}\")\n",
    "    assert False, \"Stage 1 (generate_dets_embs) failed.\"\n",
    "except Exception as e:\n",
    "    log.error(f\"--- Stage 1 FAILED with unexpected error ---\")\n",
    "    log.error(f\"Error: {e}\")\n",
    "    assert False, \"Stage 1 (generate_dets_embs) failed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de5cdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 경로 확인\n",
    "!ls -l /home/kms2069/Projects/boxmot/runs/mot_eval_notebook/ByteTrack/polyp_test_4_gt_04-1/tracks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999bfb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 7 (수정됨 - 타입 강제 변환 및 디버깅 추가) ---\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import pandas as pd # 이전 셀에서 필요할 수 있음\n",
    "import logging\n",
    "import motmetrics as mm # 이전 셀에서 필요할 수 있음\n",
    "import numpy as np # 이전 셀에서 필요할 수 있음\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "log.info(\"--- Stage 2: Generating MOT Results ---\")\n",
    "stage2_failed = False\n",
    "mot_exp_folders = {} # 알고리즘별 결과 폴더 저장\n",
    "\n",
    "# Cell 5에서 정의된 변수들 사용 (경로 재확인 및 Path 객체 확인)\n",
    "output_base_dir = Path(output_dir).resolve()\n",
    "det_weights = Path(det_weights).resolve()\n",
    "reid_weights = Path(reid_weights).resolve()\n",
    "val_script_path = Path(os.path.abspath(os.path.join(cloned_boxmot_repo_path, 'val.py')))\n",
    "execution_cwd = Path(os.path.abspath(os.path.dirname(cloned_boxmot_repo_path)))\n",
    "my_env = os.environ.copy()\n",
    "existing_pythonpath = my_env.get('PYTHONPATH', '')\n",
    "my_env['PYTHONPATH'] = str(execution_cwd) + os.pathsep + existing_pythonpath\n",
    "test_set_dir = Path(test_set_dir).resolve()\n",
    "python_executable = sys.executable # 문자열이어야 함\n",
    "\n",
    "# Stage 1에서 생성된 detection/embedding 폴더 경로\n",
    "dets_folder = output_base_dir / \"dets_n_embs\" / det_weights.stem / 'dets'\n",
    "embs_folder = output_base_dir / \"dets_n_embs\" / det_weights.stem / 'embs' / reid_weights.stem\n",
    "\n",
    "if not dets_folder.is_dir() or not embs_folder.is_dir():\n",
    "    log.error(\"Detections or Embeddings folder not found from Stage 1 output.\")\n",
    "    log.error(f\"Checked dets: {dets_folder}\")\n",
    "    log.error(f\"Checked embs: {embs_folder}\")\n",
    "    assert False, \"Cannot proceed to Stage 2 without dets/embs.\"\n",
    "\n",
    "for algo in algorithms: # Cell 5에서 정의된 알고리즘 리스트\n",
    "    log.info(f\"--- Running MOT generation for Algorithm: {algo} ---\")\n",
    "\n",
    "    expected_exp_name = f\"{det_weights.stem}_{reid_weights.stem}_{algo.lower()}\"\n",
    "    mot_exp_folder = output_base_dir / 'mot' / expected_exp_name\n",
    "    mot_exp_folders[algo] = mot_exp_folder\n",
    "\n",
    "    # --- 명령어 리스트 항목 구성 (Path 객체 등 유지 가능) ---\n",
    "    cmd_stage2_items = [\n",
    "        python_executable,\n",
    "        val_script_path,\n",
    "        'generate_mot_results',\n",
    "        '--yolo-model', det_weights,\n",
    "        '--reid-model', reid_weights,\n",
    "        '--tracking-method', algo.lower(),\n",
    "        '--project', output_base_dir,\n",
    "        '--source', test_set_dir,\n",
    "        '--exist-ok',\n",
    "    ]\n",
    "    if 'device' in locals() and device is not None:\n",
    "         cmd_stage2_items.extend(['--device', device])\n",
    "\n",
    "    # --- *** 최종 명령어 리스트 생성 (모든 항목을 문자열로 변환) 및 타입 확인 *** ---\n",
    "    cmd_stage2 = []\n",
    "    log.debug(f\"Building command list for subprocess (Algorithm: {algo}):\")\n",
    "    for i, item in enumerate(cmd_stage2_items):\n",
    "        try:\n",
    "            # os.PathLike 객체 포함하여 문자열로 변환 시도\n",
    "            str_item = os.fspath(item) # os.fspath()는 str, bytes, PathLike를 경로 문자열로 변환\n",
    "            if not isinstance(str_item, str): # 혹시 fspath 결과가 str이 아니면 강제 변환\n",
    "                 str_item = str(item)\n",
    "            cmd_stage2.append(str_item)\n",
    "            # 타입 확인 로그 (디버깅 시 주석 해제)\n",
    "            # log.debug(f\"  Item {i}: Original Type={type(item)}, Final Type={type(str_item)}, Value='{str_item}'\")\n",
    "        except TypeError:\n",
    "            # os.fspath가 처리 못하는 타입이면 기본 str() 사용\n",
    "            log.warning(f\"Item {i} could not be converted using os.fspath (Type={type(item)}). Falling back to str(). Value={item}\")\n",
    "            cmd_stage2.append(str(item)) # fallback to basic str conversion\n",
    "\n",
    "    # 최종 리스트의 모든 항목이 문자열인지 다시 한번 확인 (방어적 코딩)\n",
    "    for i, item in enumerate(cmd_stage2):\n",
    "         if not isinstance(item, str):\n",
    "              log.error(f\"CRITICAL: Item {i} in final cmd_stage2 is NOT a string! Type={type(item)}, Value={item}\")\n",
    "              assert False, f\"Command list item {i} is not a string before subprocess call!\"\n",
    "    # --- *** 변환 및 확인 끝 *** ---\n",
    "\n",
    "    try:\n",
    "        # 이제 cmd_stage2의 모든 항목은 문자열이므로 join 및 실행이 안전함\n",
    "        log.info(f\"Executing Stage 2 command for {algo}: {' '.join(cmd_stage2)}\")\n",
    "        log.info(f\"    >>> in CWD: {execution_cwd} | with PYTHONPATH including: {execution_cwd}\")\n",
    "\n",
    "        result_stage2 = subprocess.run(cmd_stage2, check=True, capture_output=True, text=True,\n",
    "                                       encoding='utf-8', cwd=execution_cwd, env=my_env)\n",
    "        log.info(f\"--- Stage 2 for {algo} Finished Successfully ---\")\n",
    "        log.info(f\"Expected MOT results folder: {mot_exp_folder} (may have _suffix if exists)\")\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        log.error(f\"--- Stage 2 for {algo} FAILED ---\")\n",
    "        log.error(f\"Return code: {e.returncode}\")\n",
    "        log.error(f\"Stderr: {e.stderr.strip()}\")\n",
    "        log.error(f\"Stdout: {e.stdout.strip()}\")\n",
    "        stage2_failed = True\n",
    "    except Exception as e:\n",
    "        log.error(f\"--- Stage 2 for {algo} FAILED with unexpected error ---\")\n",
    "        log.error(f\"Error: {e}\") # 여기서 이전 오류 메시지가 출력되었을 것임\n",
    "        log.debug(f\"Traceback: \", exc_info=True) # 상세 트레이스백\n",
    "        stage2_failed = True\n",
    "\n",
    "if stage2_failed:\n",
    "     assert False, \"Stage 2 (generate_mot_results) failed for one or more algorithms.\"\n",
    "else:\n",
    "     log.info(\"--- Stage 2 Finished for all algorithms ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30186679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 8 (Replaced - Evaluation using motmetrics) ---\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import logging\n",
    "import motmetrics as mm # motmetrics import\n",
    "import numpy as np\n",
    "import glob # glob import\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "# --- Helper Function (Unique ID Counting) ---\n",
    "def count_unique_ids_from_file(filepath):\n",
    "    \"\"\"Counts unique track IDs from a MOT result file.\"\"\"\n",
    "    filepath = Path(filepath) # Ensure it's a Path object\n",
    "    if not filepath.is_file(): return 0, set() # Return count 0 and empty set\n",
    "    try:\n",
    "        # Read only the ID column (index 1) for efficiency\n",
    "        data = pd.read_csv(filepath, header=None, sep=',|\\s+', engine='python', usecols=[1])\n",
    "        if data.empty: return 0, set()\n",
    "        # Get unique IDs, convert to integer type for safety if needed, exclude -1\n",
    "        unique_ids = data[1].astype(int).unique()\n",
    "        unique_ids = unique_ids[unique_ids != -1]\n",
    "        return len(unique_ids), set(unique_ids) # Return count and the set of IDs\n",
    "    except Exception as e:\n",
    "        log.error(f\"Error reading/counting IDs in {filepath}: {e}\")\n",
    "        return 0, set()\n",
    "\n",
    "log.info(\"--- Running Evaluation using motmetrics on generated MOT files ---\")\n",
    "final_results = {}\n",
    "evaluation_failed_algos = []\n",
    "\n",
    "# Get needed paths/variables from Cell 5\n",
    "# Cell 5에서 output_dir, det_weights, reid_weights, test_set_dir, algorithms, iou_threshold 등이 정의되어 있어야 함\n",
    "output_base_dir = Path(output_dir).resolve()\n",
    "det_weights = Path(det_weights)\n",
    "reid_weights = Path(reid_weights)\n",
    "test_set_dir = Path(test_set_dir).resolve()\n",
    "# iou_threshold = iou_threshold # Cell 5에서 정의된 iou_threshold 사용 가정\n",
    "\n",
    "for algo in algorithms: # Cell 5 algorithms list\n",
    "    log.info(f\"--- Evaluating Algorithm: {algo} ---\")\n",
    "    accumulators = [] # Accumulators for sequences of this algo\n",
    "    total_algo_track_ids = set() # Set to store unique track IDs across all sequences for this algo\n",
    "\n",
    "    # --- Find the MOT result folder for this algorithm ---\n",
    "    expected_exp_name_base = f\"{det_weights.stem}_{reid_weights.stem}_{algo.lower()}\"\n",
    "    search_pattern = str(output_base_dir / 'mot' / f\"{expected_exp_name_base}*\")\n",
    "    possible_folders = sorted(glob.glob(search_pattern))\n",
    "    mot_folder_to_eval = None\n",
    "\n",
    "    if not possible_folders:\n",
    "        log.error(f\"Could not find MOT result folder for {algo} matching pattern: {search_pattern}\")\n",
    "        evaluation_failed_algos.append(algo)\n",
    "        # Add NaN placeholder for this algorithm\n",
    "        final_results[algo] = {'MOTA': np.nan, 'IDF1': np.nan, 'IDSW': np.nan, 'IDS': np.nan, 'GT-IDS': np.nan}\n",
    "        continue # Skip to next algorithm\n",
    "\n",
    "    # Use the last found folder (assuming latest if multiple exist due to increment_path)\n",
    "    mot_folder_to_eval = Path(possible_folders[-1])\n",
    "    if not mot_folder_to_eval.is_dir():\n",
    "        log.error(f\"Path found for {algo} is not a directory: {mot_folder_to_eval}\")\n",
    "        evaluation_failed_algos.append(algo)\n",
    "        final_results[algo] = {'MOTA': np.nan, 'IDF1': np.nan, 'IDSW': np.nan, 'IDS': np.nan, 'GT-IDS': np.nan}\n",
    "        continue\n",
    "    log.info(f\"Found MOT result folder for {algo}: {mot_folder_to_eval}\")\n",
    "\n",
    "    # --- Iterate through sequence result files (.txt) in the folder ---\n",
    "    found_results_files = False\n",
    "    mot_txt_files = sorted(mot_folder_to_eval.glob('*.txt'))\n",
    "\n",
    "    if not mot_txt_files:\n",
    "         log.warning(f\"No MOT result files (.txt) found in {mot_folder_to_eval} for algorithm {algo}.\")\n",
    "         # evaluation_failed_algos.append(algo) # Mark as failed only if no sequences succeed later\n",
    "         # continue # Continue to calculation phase, result will be NaN\n",
    "\n",
    "    for trk_file_path in mot_txt_files:\n",
    "        seq_name = trk_file_path.stem\n",
    "        gt_file_path = test_set_dir / seq_name / 'gt' / 'gt.txt'\n",
    "\n",
    "        if not gt_file_path.is_file():\n",
    "            log.warning(f\"  Ground truth file not found for sequence {seq_name} at {gt_file_path}. Skipping this sequence.\")\n",
    "            continue\n",
    "\n",
    "        log.info(f\"  Processing sequence: {seq_name} (GT: {gt_file_path}, Track: {trk_file_path})\")\n",
    "        found_results_files = True # Mark that we found at least one result file\n",
    "\n",
    "        try:\n",
    "            # Load GT and Tracker data\n",
    "            gt = mm.io.loadtxt(str(gt_file_path), fmt=\"mot15-2D\", min_confidence=-1)\n",
    "            ts = mm.io.loadtxt(str(trk_file_path), fmt=\"mot15-2D\") # Load the MOT format file\n",
    "            # Create and update accumulator for this sequence\n",
    "            acc = mm.MOTAccumulator(auto_id=True)\n",
    "            valid_gt_frames = gt.index.get_level_values('FrameId').unique()\n",
    "            valid_ts_frames = ts.index.get_level_values('FrameId').unique() if not ts.empty else []\n",
    "\n",
    "            for frame_id in valid_gt_frames:\n",
    "                gt_frame = gt.loc[frame_id]\n",
    "                gt_ids = gt_frame.index.get_level_values('Id').tolist()\n",
    "\n",
    "                # 현재 프레임에 대한 tracker 결과 확인 (존재하고 비어있지 않은지)\n",
    "                if frame_id in valid_ts_frames and not ts.loc[[frame_id]].empty: # Use .loc[[frame_id]] to keep DataFrame structure even for one row\n",
    "                    ts_frame = ts.loc[frame_id]\n",
    "                    # Check if ts_frame still unexpectedly became non-DataFrame or lost columns\n",
    "                    if not isinstance(ts_frame, pd.DataFrame) or not {'X', 'Y', 'Width', 'Height'}.issubset(ts_frame.columns):\n",
    "                         log.warning(f\"    Frame {frame_id}: ts_frame is invalid or missing columns after loading. Skipping update.\")\n",
    "                         trk_ids = []\n",
    "                         distances = np.empty((len(gt_ids), 0))\n",
    "                    else:\n",
    "                         trk_ids = ts_frame.index.get_level_values('Id').tolist()\n",
    "                         # 거리 계산 (이제 ts_frame에 컬럼이 있음이 보장됨)\n",
    "                         distances = mm.distances.iou_matrix(gt_frame[['X', 'Y', 'Width', 'Height']],\n",
    "                                                              ts_frame[['X', 'Y', 'Width', 'Height']],\n",
    "                                                              max_iou=iou_threshold) # Cell 5의 iou_threshold 사용\n",
    "                else:\n",
    "                    # 현재 프레임에 추적 결과 없음\n",
    "                    trk_ids = []\n",
    "                    # 거리 행렬은 (num_gt, num_tr) 형태로, num_tr=0 이므로 (len(gt_ids), 0) 형태\n",
    "                    distances = np.empty((len(gt_ids), 0))\n",
    "\n",
    "                # Accumulator 업데이트 (trk_ids나 distances가 비어있어도 motmetrics가 처리)\n",
    "                acc.update(gt_ids, trk_ids, distances)\n",
    "            accumulators.append(acc) # Store accumulator for this sequence\n",
    "\n",
    "            # --- Aggregate unique track IDs ---\n",
    "            # Count unique IDs from the current tracker file and add to the set for the algorithm\n",
    "            _, unique_ids_in_seq_set = count_unique_ids_from_file(trk_file_path)\n",
    "            total_algo_track_ids.update(unique_ids_in_seq_set)\n",
    "            # log.debug(f\"    Sequence {seq_name} unique track IDs: {len(unique_ids_in_seq_set)}. Total unique for {algo} so far: {len(total_algo_track_ids)}\")\n",
    "\n",
    "        except ValueError as load_err:\n",
    "            # 위 수정에도 불구하고 KeyError 발생 시 (파일 자체의 컬럼 문제)\n",
    "             log.error(f\"    KeyError processing sequence {seq_name} for {algo}: {e}\")\n",
    "             log.error(f\"    This likely means columns 'X', 'Y', 'Width', 'Height' are missing in the source GT or Tracker file.\")\n",
    "             log.warning(f\"    Please verify the format of {gt_file_path} and {trk_file_path}.\")\n",
    "             evaluation_failed_algos.append(algo + f\"_{seq_name}\")\n",
    "        except ValueError as load_err:\n",
    "            log.error(f\"    Failed to load GT ({gt_file_path}) or Tracker ({trk_file_path}) file. Check format. Error: {load_err}\")\n",
    "            evaluation_failed_algos.append(algo + f\"_{seq_name}\")\n",
    "        except Exception as e:\n",
    "            log.error(f\"    Error processing sequence {seq_name} for {algo}: {e}\")\n",
    "            log.debug(f\"Traceback:\", exc_info=True)\n",
    "            evaluation_failed_algos.append(algo + f\"_{seq_name}\")\n",
    "\n",
    "\n",
    "    # --- Calculate Combined Metrics for the Algorithm ---\n",
    "    if not accumulators:\n",
    "        # This happens if no txt files were found OR all sequences failed during loading/processing\n",
    "        log.warning(f\"No valid sequence data accumulated for algorithm {algo}. Cannot calculate combined metrics.\")\n",
    "        if algo not in evaluation_failed_algos: evaluation_failed_algos.append(algo)\n",
    "        # Use total count of IDs found (even from failed sequences if files existed)\n",
    "        final_results[algo] = {'MOTA': np.nan, 'IDF1': np.nan, 'IDSW': np.nan, 'IDS': len(total_algo_track_ids), 'GT-IDS': np.nan}\n",
    "        continue # Skip metric calculation\n",
    "\n",
    "    try:\n",
    "        mh = mm.metrics.create()\n",
    "        # Combine accumulators for all successfully processed sequences of this algorithm\n",
    "        combined_acc = mm.MOTAccumulator.merge_event_dataframes(accumulators)\n",
    "\n",
    "        # Calculate combined metrics including switches (IDSW) and unique GT objects (GT-IDS)\n",
    "        summary = mh.compute(combined_acc, metrics=['mota', 'idf1', 'num_switches', 'num_unique_objects'], name=f'{algo}_Combined')\n",
    "\n",
    "        # Store results in the desired format\n",
    "        final_results[algo] = {\n",
    "            'MOTA': summary['mota'].iloc[0],\n",
    "            'IDF1': summary['idf1'].iloc[0],\n",
    "            'IDSW': summary['num_switches'].iloc[0],           # ID Switches from motmetrics\n",
    "            'IDS': len(total_algo_track_ids),                  # Aggregated Count of unique Track IDs\n",
    "            'GT-IDS': summary['num_unique_objects'].iloc[0]    # Unique Ground Truth IDs from motmetrics\n",
    "        }\n",
    "        log.info(f\"Combined metrics calculated for {algo}: {final_results[algo]}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        log.error(f\"Error calculating combined metrics for {algo}: {e}\")\n",
    "        log.debug(f\"Traceback:\", exc_info=True)\n",
    "        if algo not in evaluation_failed_algos: evaluation_failed_algos.append(algo)\n",
    "        # Still report the counted IDs if available\n",
    "        final_results[algo] = {'MOTA': np.nan, 'IDF1': np.nan, 'IDSW': np.nan, 'IDS': len(total_algo_track_ids), 'GT-IDS': np.nan}\n",
    "\n",
    "\n",
    "# --- Final Result Table ---\n",
    "log.info(\"\\n--- Final Evaluation Metrics (using motmetrics) ---\")\n",
    "if final_results:\n",
    "    final_results_df = pd.DataFrame.from_dict(final_results, orient='index')\n",
    "\n",
    "    # Reorder columns as requested by user\n",
    "    requested_cols = ['MOTA', 'IDF1', 'IDSW', 'IDS', 'GT-IDS']\n",
    "    # Filter DataFrame to include only requested columns that actually exist\n",
    "    cols_to_show = [col for col in requested_cols if col in final_results_df.columns]\n",
    "\n",
    "    if not final_results_df.empty and cols_to_show:\n",
    "        final_results_df = final_results_df[cols_to_show]\n",
    "        print(final_results_df) # Print the final table\n",
    "\n",
    "        # Save to CSV\n",
    "        final_csv_path = output_base_dir / \"final_evaluation_metrics_motmetrics.csv\"\n",
    "        try:\n",
    "            final_results_df.to_csv(final_csv_path)\n",
    "            log.info(f\"Final metrics saved to: {final_csv_path}\")\n",
    "        except Exception as e:\n",
    "            log.error(f\"Failed to save final metrics to CSV: {e}\")\n",
    "    else:\n",
    "         log.warning(\"Final results DataFrame is empty or missing requested columns.\")\n",
    "else:\n",
    "    log.warning(\"No final evaluation results were generated.\")\n",
    "\n",
    "if evaluation_failed_algos:\n",
    "    log.error(f\"Evaluation failed for the following algorithms/sequences: {evaluation_failed_algos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee33c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 9: Results Visualization ---\n",
    "from tqdm import tqdm \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os # os 모듈 임포트 확인\n",
    "from pathlib import Path # Path 임포트 확인\n",
    "import seaborn\n",
    "\n",
    "log = logging.getLogger(__name__) # 로거 가져오기 (Cell 3에서 설정됨)\n",
    "\n",
    "# Cell 8에서 생성된 DataFrame 사용 시도, 없으면 CSV 파일 로드\n",
    "results_df = None\n",
    "if 'final_results_df' in locals() and isinstance(final_results_df, pd.DataFrame) and not final_results_df.empty:\n",
    "    results_df = final_results_df\n",
    "    log.info(\"Using existing final_results_df DataFrame for plotting.\")\n",
    "else:\n",
    "    # Cell 8에서 저장한 CSV 경로 (Cell 5의 output_dir 사용)\n",
    "    output_base_dir = Path(output_dir).resolve() # output_dir은 Cell 5에서 정의됨\n",
    "    csv_path = output_base_dir / \"results_yolov8m_0.1_msmt\"     ### 시각화 원하는 csv 파일일\n",
    "    if csv_path.is_file():\n",
    "        try:\n",
    "            results_df = pd.read_csv(csv_path, index_col='Algorithm') # Algorithm 컬럼을 인덱스로 사용\n",
    "            log.info(f\"Loaded results from {csv_path} for plotting.\")\n",
    "        except Exception as e:\n",
    "            log.error(f\"Failed to load results from CSV {csv_path}: {e}\")\n",
    "    else:\n",
    "        log.error(\"Could not find existing DataFrame or CSV file to plot results.\")\n",
    "\n",
    "# --- Plotting ---\n",
    "if results_df is not None and not results_df.empty:\n",
    "\n",
    "    # 그래프 스타일 설정 (선택 사항)\n",
    "    plt.style.use('seaborn-v0_8-darkgrid') # ggplot \n",
    "\n",
    "    # 1. MOTA 비교\n",
    "    if 'MOTA' in results_df.columns:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        results_df['MOTA'].sort_values(ascending=False).plot(kind='bar', color=['skyblue', 'lightcoral', 'lightgreen'])\n",
    "        plt.title('MOTA Comparison')\n",
    "        plt.ylabel('MOTA Score')\n",
    "        plt.xlabel('Tracker Algorithm')\n",
    "        plt.xticks(rotation=0)\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # 2. IDF1 비교\n",
    "    if 'IDF1' in results_df.columns:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        results_df['IDF1'].sort_values(ascending=False).plot(kind='bar', color=['skyblue', 'lightcoral', 'lightgreen'])\n",
    "        plt.title('IDF1 Comparison')\n",
    "        plt.ylabel('IDF1 Score')\n",
    "        plt.xlabel('Tracker Algorithm')\n",
    "        plt.xticks(rotation=0)\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # 3. IDSW 비교\n",
    "    if 'IDSW' in results_df.columns:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        results_df['IDSW'].sort_values().plot(kind='bar', color=['skyblue', 'lightcoral', 'lightgreen']) # 낮은 값이 좋으므로 오름차순 정렬\n",
    "        plt.title('ID Switches (IDSW) Comparison')\n",
    "        plt.ylabel('Number of Switches')\n",
    "        plt.xlabel('Tracker Algorithm')\n",
    "        plt.xticks(rotation=0)\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # 4. IDS (Count-IDs) vs GT-IDS 비교 (Grouped Bar Chart)\n",
    "    if 'IDS' in results_df.columns and 'GT-IDS' in results_df.columns:\n",
    "        # NaN 값을 가진 알고리즘은 제외하거나 0으로 처리 필요\n",
    "        plot_df = results_df[['IDS', 'GT-IDS']].dropna() # NaN 있는 행 제외\n",
    "\n",
    "        if not plot_df.empty:\n",
    "            ax = plot_df.plot(kind='bar', figsize=(10, 6), color=['lightcoral', 'darkgrey']) # IDS(추적), GT-IDS(실제) 색 구분\n",
    "            plt.title('ID Count Comparison (Tracked vs Ground Truth)')\n",
    "            plt.ylabel('Number of Unique IDs')\n",
    "            plt.xlabel('Tracker Algorithm')\n",
    "            plt.xticks(rotation=0)\n",
    "            plt.legend(['Tracked IDs (Count-IDs)', 'Ground Truth IDs'])\n",
    "            plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "            # 각 막대 위에 숫자 표시 (선택 사항)\n",
    "            for container in ax.containers:\n",
    "                ax.bar_label(container)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            log.warning(\"Not enough valid data to plot IDS vs GT-IDS comparison after dropping NaN.\")\n",
    "\n",
    "else:\n",
    "    log.error(\"Cannot generate plots because evaluation results are not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b543d44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 10 (Revised - Fix CSV Loading) ---\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "# --- !!! 중요: 각 실험 결과 CSV 파일 경로를 지정하세요 !!! ---\n",
    "results_csv_paths = {\n",
    "    'YOLOv8s': '/home/kms2069/Projects/boxmot/runs/mot_eval_notebook_val/results_yolov8s_0.82_polyp.csv',  # <--- 경로 확인!\n",
    "    'YOLOv8m': '/home/kms2069/Projects/boxmot/runs/mot_eval_notebook_val/results_yolov8m_0.82_polyp_2.csv',  # <--- 경로 확인!\n",
    "}\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "# --- 데이터 로드 (수정됨) ---\n",
    "loaded_data = {}\n",
    "plot_ready = True\n",
    "common_algorithms_index = None\n",
    "\n",
    "log.info(\"--- Loading result files for comparison plotting ---\")\n",
    "for exp_name, csv_path_str in results_csv_paths.items():\n",
    "    log.info(f\"Loading results for experiment: '{exp_name}' from {csv_path_str}\")\n",
    "    csv_path = Path(csv_path_str)\n",
    "    if csv_path.is_file():\n",
    "        try:\n",
    "            # --- *** 수정된 부분: index_col=0 사용 *** ---\n",
    "            # 첫 번째 컬럼을 인덱스로 사용 (기본 저장 시 인덱스 이름이 없음)\n",
    "            df = pd.read_csv(csv_path, index_col=0)\n",
    "            # 인덱스 이름 설정 (선택 사항이지만 권장)\n",
    "            df.index.name = 'Algorithm'\n",
    "            # --- *** 수정 끝 *** ---\n",
    "\n",
    "            loaded_data[exp_name] = df\n",
    "            log.info(f\"  Successfully loaded {len(df)} rows.\")\n",
    "            if common_algorithms_index is None:\n",
    "                common_algorithms_index = df.index\n",
    "            else:\n",
    "                common_algorithms_index = common_algorithms_index.intersection(df.index)\n",
    "        except Exception as e:\n",
    "            log.error(f\"  Failed to load or process CSV {csv_path}: {e}\")\n",
    "            plot_ready = False\n",
    "    else:\n",
    "        log.error(f\"  CSV file not found at: {csv_path}\")\n",
    "        plot_ready = False\n",
    "\n",
    "# --- Plotting ---\n",
    "if plot_ready and loaded_data:\n",
    "    # ... (나머지 플로팅 코드는 이전과 동일하게 유지) ...\n",
    "\n",
    "    if common_algorithms_index is None or common_algorithms_index.empty:\n",
    "         log.error(\"No common algorithms found across the loaded result files or no files loaded. Cannot plot.\")\n",
    "         plot_ready = False\n",
    "\n",
    "    if plot_ready:\n",
    "        plt.style.use('ggplot')\n",
    "        metrics_to_plot = ['MOTA', 'IDF1', 'IDSW', 'IDS', 'GT-IDS']\n",
    "        y_labels = {\n",
    "        'MOTA': 'MOTA Score',\n",
    "        'IDF1': 'IDF1 Score',\n",
    "        'IDSW': 'Number of Switches',\n",
    "        'IDS': 'Number of Count IDs',           \n",
    "        'GT-IDS': 'Number of Ground Truth IDs'\n",
    "        }\n",
    "        lower_is_better = ['IDSW']\n",
    "\n",
    "        for metric in metrics_to_plot:\n",
    "            # ... (rest of plotting logic is unchanged) ...\n",
    "            log.info(f\"Generating plot for metric: {metric}\")\n",
    "            metric_data = {}\n",
    "            valid_metric_in_all = True\n",
    "            for exp_name, df in loaded_data.items():\n",
    "                if metric in df.columns:\n",
    "                    metric_data[exp_name] = df.loc[common_algorithms_index, metric]\n",
    "                else:\n",
    "                    log.warning(f\"Metric '{metric}' not found in results for '{exp_name}'. Skipping this metric plot.\")\n",
    "                    valid_metric_in_all = False\n",
    "                    break\n",
    "\n",
    "            if not valid_metric_in_all or not metric_data:\n",
    "                continue\n",
    "\n",
    "            compare_df = pd.DataFrame(metric_data)\n",
    "            compare_df = compare_df.dropna()\n",
    "\n",
    "            if compare_df.empty:\n",
    "                log.warning(f\"No valid data to plot for metric '{metric}' after dropping NaN or filtering algorithms.\")\n",
    "                continue\n",
    "\n",
    "            first_exp_name = list(loaded_data.keys())[0]\n",
    "            ascending_order = metric in lower_is_better\n",
    "            compare_df = compare_df.sort_values(by=first_exp_name, ascending=ascending_order)\n",
    "\n",
    "            num_experiments = len(compare_df.columns)\n",
    "            ax = compare_df.plot(kind='bar', figsize=(6 + num_experiments * 2, 6), edgecolor='grey', width=0.8)\n",
    "            plt.title(f'Across Comparison about {metric} ')\n",
    "            plt.ylabel(y_labels.get(metric, metric))\n",
    "            plt.xlabel('Tracker Algorithm')\n",
    "            plt.xticks(rotation=0)\n",
    "            plt.legend(title='Detector')\n",
    "            plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "            for container in ax.containers:\n",
    "                fmt = '%.3f' if metric in ['MOTA', 'IDF1'] else '%d'\n",
    "                try:\n",
    "                    ax.bar_label(container, fmt=fmt, padding=3, fontsize=8, rotation=0)\n",
    "                except Exception as label_e:\n",
    "                     log.warning(f\"Could not add bar labels for {metric}: {label_e}\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "else:\n",
    "    log.error(\"Cannot generate comparison plots. Ensure all specified CSV files exist and contain valid data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d3d809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "# --- !!! 중요: 각 실험 결과 CSV 파일 경로를 지정하세요 !!! ---\n",
    "results_csv_paths = {\n",
    "    'YOLOv8s': '/home/kms2069/Projects/boxmot/runs/mot_eval_notebook_val/results_yolov8s_0.82_polyp.csv',  # <--- 경로 확인!\n",
    "    'YOLOv8m': '/home/kms2069/Projects/boxmot/runs/mot_eval_notebook_val/results_yolov8m_0.82_polyp_2.csv',  # <--- 경로 확인!\n",
    "}\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "# --- 데이터 로드 ---\n",
    "loaded_data = {}\n",
    "plot_ready = True\n",
    "common_algorithms_index = None\n",
    "\n",
    "log.info(\"--- Loading result files for comparison plotting ---\")\n",
    "for exp_name, csv_path_str in results_csv_paths.items():\n",
    "    log.info(f\"Loading results for experiment: '{exp_name}' from {csv_path_str}\")\n",
    "    csv_path = Path(csv_path_str)\n",
    "    if csv_path.is_file():\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path, index_col=0) # 첫 번째 컬럼을 인덱스로 사용\n",
    "            df.index.name = 'Algorithm' # 인덱스 이름 명시\n",
    "            loaded_data[exp_name] = df\n",
    "            log.info(f\"  Successfully loaded {len(df)} rows.\")\n",
    "            if common_algorithms_index is None:\n",
    "                common_algorithms_index = df.index\n",
    "            else:\n",
    "                common_algorithms_index = common_algorithms_index.intersection(df.index)\n",
    "        except Exception as e:\n",
    "            log.error(f\"  Failed to load or process CSV {csv_path}: {e}\")\n",
    "            plot_ready = False\n",
    "    else:\n",
    "        log.error(f\"  CSV file not found at: {csv_path}\")\n",
    "        plot_ready = False\n",
    "\n",
    "# --- Plotting ---\n",
    "if plot_ready and loaded_data:\n",
    "\n",
    "    if common_algorithms_index is None or common_algorithms_index.empty:\n",
    "         log.error(\"No common algorithms found across the loaded result files or no files loaded. Cannot plot.\")\n",
    "         plot_ready = False\n",
    "\n",
    "    if plot_ready:\n",
    "        plt.style.use('seaborn-v0_8-darkgrid') # ggplot\n",
    "\n",
    "        # 일반 지표 플로팅 (MOTA, IDF1, IDSW) - 이전과 동일하게 유지\n",
    "        metrics_to_plot_individual = ['MOTA', 'IDF1', 'IDSW']\n",
    "        y_labels_individual = {\n",
    "            'MOTA': 'MOTA Score', 'IDF1': 'IDF1 Score', 'IDSW': 'Number of Switches'\n",
    "        }\n",
    "        lower_is_better_individual = ['IDSW']\n",
    "\n",
    "        for metric in metrics_to_plot_individual:\n",
    "            log.info(f\"Generating plot for metric: {metric}\")\n",
    "            metric_data = {}\n",
    "            valid_metric_in_all = True\n",
    "            for exp_name, df in loaded_data.items():\n",
    "                if metric in df.columns:\n",
    "                    metric_data[exp_name] = df.loc[common_algorithms_index, metric]\n",
    "                else:\n",
    "                    log.warning(f\"Metric '{metric}' not found in results for '{exp_name}'. Skipping this metric plot.\")\n",
    "                    valid_metric_in_all = False\n",
    "                    break\n",
    "            if not valid_metric_in_all or not metric_data: continue\n",
    "            compare_df = pd.DataFrame(metric_data).dropna()\n",
    "            if compare_df.empty:\n",
    "                log.warning(f\"No valid data to plot for metric '{metric}' after dropping NaN or filtering algorithms.\")\n",
    "                continue\n",
    "\n",
    "            first_exp_name = list(loaded_data.keys())[0]\n",
    "            ascending_order = metric in lower_is_better_individual\n",
    "            compare_df = compare_df.sort_values(by=first_exp_name, ascending=ascending_order)\n",
    "            num_experiments = len(compare_df.columns)\n",
    "            ax = compare_df.plot(kind='bar', figsize=(6 + num_experiments * 2, 6), edgecolor='grey', width=0.8)\n",
    "            plt.title(f'{metric} Comparison across Detectors')\n",
    "            plt.ylabel(y_labels_individual.get(metric, metric))\n",
    "            plt.xlabel('Tracker Algorithm')\n",
    "            plt.xticks(rotation=0)\n",
    "            plt.legend(title='Detector Basis')\n",
    "            plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "            for container in ax.containers:\n",
    "                fmt = '%.3f' if metric in ['MOTA', 'IDF1'] else '%d'\n",
    "                try: ax.bar_label(container, fmt=fmt, padding=3, fontsize=8, rotation=0)\n",
    "                except Exception as label_e: log.warning(f\"Could not add bar labels for {metric}: {label_e}\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        # --- *** 수정된 ID Count vs GT ID 통합 비교 그래프 *** ---\n",
    "        log.info(\"Generating combined ID Count vs GT ID plot\")\n",
    "        plot_data_ids_gt = {}\n",
    "        experiments = list(loaded_data.keys()) # 예: ['YOLOv8s', 'YOLOv8m']\n",
    "\n",
    "        for algo in common_algorithms_index:\n",
    "            algo_data = {}\n",
    "            for exp_name in experiments:\n",
    "                df = loaded_data[exp_name]\n",
    "                if 'IDS' in df.columns and 'GT-IDS' in df.columns:\n",
    "                    # 각 실험(Detector)별로 IDS와 GT-IDS 값을 가져옴\n",
    "                    algo_data[f'{exp_name} IDS'] = df.loc[algo, 'IDS']\n",
    "                    # GT-IDS는 Detector에 따라 달라질 수 있으므로, 해당 실험의 GT-IDS를 사용\n",
    "                    algo_data[f'{exp_name} GT-IDS'] = df.loc[algo, 'GT-IDS']\n",
    "                else:\n",
    "                    log.warning(f\"IDS or GT-IDS not found for {algo} in {exp_name}. Plot may be incomplete.\")\n",
    "                    # 값이 없을 경우 NaN으로 채워서 DataFrame 구조 유지\n",
    "                    algo_data[f'{exp_name} IDS'] = np.nan\n",
    "                    algo_data[f'{exp_name} GT-IDS'] = np.nan\n",
    "            plot_data_ids_gt[algo] = algo_data\n",
    "\n",
    "        compare_ids_gt_df = pd.DataFrame.from_dict(plot_data_ids_gt, orient='index')\n",
    "\n",
    "        if not compare_ids_gt_df.empty:\n",
    "            # 컬럼 순서 정의 (예: s_IDS, s_GT, m_IDS, m_GT)\n",
    "            column_order = []\n",
    "            colors = []\n",
    "            color_map = {'IDS': 'lightcoral', 'GT-IDS': 'darkgrey'} # 기본 색상\n",
    "            detector_colors = {'YOLOv8s': ['salmon', 'grey'], 'YOLOv8m': ['skyblue', 'dimgrey']} # Detector별 색상 쌍\n",
    "\n",
    "            for exp_name in experiments:\n",
    "                ids_col_name = f'{exp_name} IDS'\n",
    "                gt_col_name = f'{exp_name} GT-IDS'\n",
    "                if ids_col_name in compare_ids_gt_df.columns:\n",
    "                    column_order.append(ids_col_name)\n",
    "                    colors.append(detector_colors.get(exp_name, ['blue', 'black'])[0]) # Detector별 IDS 색상\n",
    "                if gt_col_name in compare_ids_gt_df.columns:\n",
    "                    column_order.append(gt_col_name)\n",
    "                    colors.append(detector_colors.get(exp_name, ['blue', 'black'])[1]) # Detector별 GT-IDS 색상\n",
    "\n",
    "            compare_ids_gt_df = compare_ids_gt_df[column_order] # 컬럼 순서 적용\n",
    "\n",
    "            ax = compare_ids_gt_df.plot(kind='bar', figsize=(8 + len(experiments) * 2, 7),\n",
    "                                         edgecolor='grey', width=0.8, color=colors if len(colors) == len(column_order) else None) # 색상 적용\n",
    "\n",
    "            plt.title('Across Comparison ID Counts and Ground Truth')\n",
    "            plt.ylabel('Number of Unique IDs')\n",
    "            plt.xlabel('Tracker Algorithm')\n",
    "            plt.xticks(rotation=0)\n",
    "            # 범례 핸들링이 복잡해질 수 있으므로, 필요시 수동 생성 또는 색상으로 구분\n",
    "            # plt.legend(title='Metric (Detector Specific)')\n",
    "            plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "            for container in ax.containers:\n",
    "                try: ax.bar_label(container, fmt='%d', padding=3, fontsize=8, rotation=0)\n",
    "                except Exception as label_e: log.warning(f\"Could not add bar labels for ID/GT-ID plot: {label_e}\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            log.warning(\"Not enough data to plot ID Count vs GT ID comparison.\")\n",
    "else:\n",
    "    log.error(\"Cannot generate comparison plots. Ensure all specified CSV files exist and contain valid data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae219a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Cell 10 (Plotting Cell - YOLOv8s 기반의 IDS, YOLOv8m 기반의 IDS, 그리고 YOLOv8m 기반의 GT-IDS만을 함께 비교) ---\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "# --- !!! 중요: 각 실험 결과 CSV 파일 경로를 지정하세요 !!! ---\n",
    "results_csv_paths = {\n",
    "    'YOLOv8s': '/home/kms2069/Projects/boxmot/runs/mot_eval_notebook_val/results_yolov8s_0.82_polyp.csv',  # <--- 경로 확인!\n",
    "    'YOLOv8m': '/home/kms2069/Projects/boxmot/runs/mot_eval_notebook_val/results_yolov8m_0.82_polyp_2.csv',  # <--- 경로 확인!\n",
    "}\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "# --- 데이터 로드 ---\n",
    "loaded_data = {}\n",
    "plot_ready = True\n",
    "common_algorithms_index = None\n",
    "\n",
    "log.info(\"--- Loading result files for comparison plotting ---\")\n",
    "for exp_name, csv_path_str in results_csv_paths.items():\n",
    "    log.info(f\"Loading results for experiment: '{exp_name}' from {csv_path_str}\")\n",
    "    csv_path = Path(csv_path_str)\n",
    "    if csv_path.is_file():\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path, index_col=0)\n",
    "            df.index.name = 'Algorithm'\n",
    "            loaded_data[exp_name] = df\n",
    "            log.info(f\"  Successfully loaded {len(df)} rows.\")\n",
    "            if common_algorithms_index is None:\n",
    "                common_algorithms_index = df.index\n",
    "            else:\n",
    "                common_algorithms_index = common_algorithms_index.intersection(df.index)\n",
    "        except Exception as e:\n",
    "            log.error(f\"  Failed to load or process CSV {csv_path}: {e}\")\n",
    "            plot_ready = False\n",
    "    else:\n",
    "        log.error(f\"  CSV file not found at: {csv_path}\")\n",
    "        plot_ready = False\n",
    "\n",
    "# --- Plotting ---\n",
    "if plot_ready and loaded_data:\n",
    "\n",
    "    if common_algorithms_index is None or common_algorithms_index.empty:\n",
    "         log.error(\"No common algorithms found across the loaded result files or no files loaded. Cannot plot.\")\n",
    "         plot_ready = False\n",
    "\n",
    "    if plot_ready:\n",
    "        plt.style.use('ggplot')\n",
    "\n",
    "        # --- 일반 지표 플로팅 (MOTA, IDF1, IDSW) ---\n",
    "        metrics_to_plot_individual = ['MOTA', 'IDF1', 'IDSW']\n",
    "        y_labels_individual = {\n",
    "            'MOTA': 'MOTA Score', 'IDF1': 'IDF1 Score', 'IDSW': 'Number of Switches'\n",
    "        }\n",
    "        lower_is_better_individual = ['IDSW']\n",
    "\n",
    "        for metric in metrics_to_plot_individual:\n",
    "            # ... (이전 답변의 MOTA, IDF1, IDSW 플로팅 로직은 동일하게 유지) ...\n",
    "            log.info(f\"Generating plot for metric: {metric}\")\n",
    "            metric_data = {}\n",
    "            valid_metric_in_all = True\n",
    "            for exp_name, df in loaded_data.items():\n",
    "                if metric in df.columns:\n",
    "                    metric_data[exp_name] = df.loc[common_algorithms_index, metric]\n",
    "                else:\n",
    "                    log.warning(f\"Metric '{metric}' not found in results for '{exp_name}'. Skipping this metric plot.\")\n",
    "                    valid_metric_in_all = False\n",
    "                    break\n",
    "            if not valid_metric_in_all or not metric_data: continue\n",
    "            compare_df = pd.DataFrame(metric_data).dropna()\n",
    "            if compare_df.empty:\n",
    "                log.warning(f\"No valid data to plot for metric '{metric}' after dropping NaN or filtering algorithms.\")\n",
    "                continue\n",
    "\n",
    "            first_exp_name_sort = list(loaded_data.keys())[0] # 정렬 기준 실험\n",
    "            ascending_order = metric in lower_is_better_individual\n",
    "            compare_df = compare_df.sort_values(by=first_exp_name_sort, ascending=ascending_order) # by 인자 수정\n",
    "            num_experiments_plot = len(compare_df.columns) # 변수 이름 수정\n",
    "            ax = compare_df.plot(kind='bar', figsize=(6 + num_experiments_plot * 2, 6), edgecolor='grey', width=0.8)\n",
    "            plt.title(f'{metric} Comparison across Detectors')\n",
    "            plt.ylabel(y_labels_individual.get(metric, metric))\n",
    "            plt.xlabel('Tracker Algorithm')\n",
    "            plt.xticks(rotation=0)\n",
    "            plt.legend(title='Detector Basis')\n",
    "            plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "            for container in ax.containers:\n",
    "                fmt = '%.3f' if metric in ['MOTA', 'IDF1'] else '%d'\n",
    "                try: ax.bar_label(container, fmt=fmt, padding=3, fontsize=8, rotation=0)\n",
    "                except Exception as label_e: log.warning(f\"Could not add bar labels for {metric}: {label_e}\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "        # --- *** 수정된 ID Count (YOLOv8s & YOLOv8m) vs. GT-IDS (YOLOv8m 기준) 비교 그래프 *** ---\n",
    "        log.info(\"Generating specific ID Count (s & m) vs. GT-IDS (m-only) plot\")\n",
    "        plot_data_specific = {}\n",
    "        yolov8s_exp_name = 'YOLOv8s' # results_csv_paths의 키와 일치해야 함\n",
    "        yolov8m_exp_name = 'YOLOv8m' # results_csv_paths의 키와 일치해야 함\n",
    "\n",
    "        # 두 실험이 모두 로드되었는지 확인\n",
    "        if yolov8s_exp_name not in loaded_data or yolov8m_exp_name not in loaded_data:\n",
    "            log.error(\"YOLOv8s and/or YOLOv8m data not found in loaded_data. Cannot generate specific ID plot.\")\n",
    "        else:\n",
    "            df_s = loaded_data[yolov8s_exp_name]\n",
    "            df_m = loaded_data[yolov8m_exp_name]\n",
    "\n",
    "            for algo in common_algorithms_index:\n",
    "                algo_data = {}\n",
    "                # YOLOv8s IDS\n",
    "                if 'IDS' in df_s.columns:\n",
    "                    algo_data[f'{yolov8s_exp_name} IDS'] = df_s.loc[algo, 'IDS']\n",
    "                else:\n",
    "                    log.warning(f\"IDS not found for {algo} in {yolov8s_exp_name} data.\")\n",
    "                    algo_data[f'{yolov8s_exp_name} IDS'] = np.nan\n",
    "\n",
    "                # YOLOv8m IDS\n",
    "                if 'IDS' in df_m.columns:\n",
    "                    algo_data[f'{yolov8m_exp_name} IDS'] = df_m.loc[algo, 'IDS']\n",
    "                else:\n",
    "                    log.warning(f\"IDS not found for {algo} in {yolov8m_exp_name} data.\")\n",
    "                    algo_data[f'{yolov8m_exp_name} IDS'] = np.nan\n",
    "\n",
    "                # YOLOv8m GT-IDS (YOLOv8m 실행 시의 GT-IDS를 기준으로 사용)\n",
    "                if 'GT-IDS' in df_m.columns:\n",
    "                    algo_data[f'{yolov8m_exp_name} GT-IDS'] = df_m.loc[algo, 'GT-IDS']\n",
    "                else:\n",
    "                    log.warning(f\"GT-IDS not found for {algo} in {yolov8m_exp_name} data.\")\n",
    "                    algo_data[f'{yolov8m_exp_name} GT-IDS'] = np.nan\n",
    "\n",
    "                plot_data_specific[algo] = algo_data\n",
    "\n",
    "            compare_specific_df = pd.DataFrame.from_dict(plot_data_specific, orient='index')\n",
    "\n",
    "            if not compare_specific_df.empty:\n",
    "                # 컬럼 순서 및 플로팅에 사용할 컬럼 정의\n",
    "                cols_for_plot = [f'{yolov8s_exp_name} IDS', f'{yolov8m_exp_name} IDS', f'{yolov8m_exp_name} GT-IDS']\n",
    "                # 실제 존재하는 컬럼만 필터링 (데이터 로딩 실패 등으로 컬럼이 없을 수 있음)\n",
    "                cols_for_plot = [col for col in cols_for_plot if col in compare_specific_df.columns]\n",
    "\n",
    "                if len(cols_for_plot) < 3: # 필요한 3개 컬럼이 모두 없으면 경고\n",
    "                     log.warning(f\"Not all required columns ({cols_for_plot}) are available for the specific ID plot. Skipping.\")\n",
    "                else:\n",
    "                    compare_specific_df = compare_specific_df[cols_for_plot].dropna() # NaN 있는 행 제거\n",
    "\n",
    "                    if not compare_specific_df.empty:\n",
    "                        # 색상 지정\n",
    "                        colors = ['skyblue', 'salmon', 'grey'] # YOLOv8s IDS, YOLOv8m IDS, YOLOv8m GT-IDS 순\n",
    "\n",
    "                        ax = compare_specific_df.plot(kind='bar', figsize=(12, 7),\n",
    "                                                     edgecolor='grey', width=0.7, color=colors)\n",
    "\n",
    "                        plt.title('ID Counts vs. GT-IDS')\n",
    "                        plt.ylabel('Number of Unique IDs')\n",
    "                        plt.xlabel('Tracker Algorithm')\n",
    "                        plt.xticks(rotation=0)\n",
    "                        # 범례는 컬럼 이름으로 자동 생성됨\n",
    "                        plt.legend(title='Metric (Detector Basis)')\n",
    "                        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "                        for container in ax.containers:\n",
    "                            try: ax.bar_label(container, fmt='%d', padding=3, fontsize=8, rotation=0)\n",
    "                            except Exception as label_e: log.warning(f\"Could not add bar labels for specific ID plot: {label_e}\")\n",
    "\n",
    "                        plt.tight_layout()\n",
    "                        plt.show()\n",
    "                    else:\n",
    "                        log.warning(\"No valid data for the specific ID Count vs GT-IDS plot after NaN drop.\")\n",
    "            else:\n",
    "                log.warning(\"Could not generate DataFrame for specific ID Count vs GT-IDS plot.\")\n",
    "\n",
    "\n",
    "        # --- GT-IDS 값 자체 비교 그래프 (선택 사항, 이전 로직대로 유지) ---\n",
    "        # 만약 GT-IDS 값이 두 실험 간에 실제로 어떻게 다른지 보고 싶다면 이 그래프도 유용\n",
    "        metric_gt_ids = 'GT-IDS'\n",
    "        if metric_gt_ids in df_s.columns and metric_gt_ids in df_m.columns:\n",
    "            log.info(f\"Generating plot for metric: {metric_gt_ids}\")\n",
    "            gt_ids_data = {\n",
    "                yolov8s_exp_name: df_s.loc[common_algorithms_index, metric_gt_ids],\n",
    "                yolov8m_exp_name: df_m.loc[common_algorithms_index, metric_gt_ids]\n",
    "            }\n",
    "            compare_gt_ids_df = pd.DataFrame(gt_ids_data).dropna()\n",
    "\n",
    "            if not compare_gt_ids_df.empty:\n",
    "                ax = compare_gt_ids_df.plot(kind='bar', figsize=(8, 5), edgecolor='grey', width=0.8)\n",
    "                plt.title('GT-IDS Comparison (across Detector runs)')\n",
    "                plt.ylabel('Number of Ground Truth IDs')\n",
    "                plt.xlabel('Tracker Algorithm')\n",
    "                plt.xticks(rotation=0)\n",
    "                plt.legend(title='Detector Basis')\n",
    "                plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "                for container in ax.containers:\n",
    "                    try: ax.bar_label(container, fmt='%d', padding=3, fontsize=8, rotation=0)\n",
    "                    except Exception as label_e: log.warning(f\"Could not add bar labels for {metric_gt_ids}: {label_e}\")\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            else:\n",
    "                log.warning(f\"No valid data to plot for {metric_gt_ids} comparison.\")\n",
    "\n",
    "else:\n",
    "    log.error(\"Cannot generate comparison plots. Ensure all specified CSV files exist and contain valid data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f37bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Source\n",
    "\n",
    "dot = \"\"\"\n",
    "digraph pipeline {\n",
    "  rankdir=LR;\n",
    "  graph [bgcolor=white];\n",
    "  node [shape=box, style=\"rounded,filled\", fontname=\"Helvetica\", fontsize=14];\n",
    "\n",
    "  \"Video sequence\" [fillcolor=\"#B3D4FC\"];\n",
    "  \"Object detector\" [fillcolor=\"#FFD8A9\"];\n",
    "  \"Data association\" [fillcolor=\"#C3FDB8\"];\n",
    "  \"Trajectory\"      [fillcolor=\"#FDC3C3\"];\n",
    "\n",
    "  \"Video sequence\" -> \"Object detector\" [arrowhead=\"vee\", penwidth=2];\n",
    "  \"Object detector\" -> \"Data association\" [arrowhead=\"vee\", penwidth=2];\n",
    "  \"Data association\" -> \"Trajectory\"     [arrowhead=\"vee\", penwidth=2];\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Render and display the styled diagram\n",
    "Source(dot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f84e02e",
   "metadata": {},
   "source": [
    "### 실행주의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacb3c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 tracking/val.py --yolo-model yolov8m_polypPNG7.4_best.pt --reid-model osnet_ain_x1_0_polyp.pt --tracking-method deepocsort botsort bytetrack --verbose --source ./assets/polyp_test_mot/train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boxmot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
